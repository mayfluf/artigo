# Aqui aprendemos sobre Dados

olá, aqui está o resumo do curso “Metodologia de DataOps’ da IBM NO COURSERA
IBM

Aqui está um resumo em tópicos:

Definição do DataOps:

Prática colaborativa de gerenciamento de dados.

Foco na comunicação, integração e automação dos fluxos de dados.

Comparação com DevOps:

Prática baseada em princípios, não um dogma rígido.

Facilita a criação e atualização de dados para atender às necessidades organizacionais.

Benefícios do DataOps:

Permite um processo repetível para análises e pipelines de dados.

Segue práticas de governança de dados e gerenciamento de modelos.

Fornece dados de alta qualidade para inteligência artificial (IA).

Público-alvo do curso:

Executivos, gerentes, vendedores, estudantes e profissionais de dados.

Abrange desde administradores de dados até engenheiros de qualidade e dados.

Objetivos da metodologia:

Garantir dados relevantes, confiáveis e rastreáveis.

Aumentar a probabilidade de obter resultados desejados.

Vantagens econômicas:

Dados confiáveis e compartilháveis.

Facilita a inovação e evita retrabalho.
Estabelecer (Established DataOps)
Preparação: Orientação para preparar a organização para o sucesso no gerenciamento de dados.

Estratégia de Dados: Investimento estratégico em canais de dados e infraestrutura, garantindo um futuro desejado antes de gastar recursos.

Equipes: Formação de equipes multidisciplinares e multifuncionais para evitar falhas de comunicação e garantir a importância do trabalho.

Automação: Implementação de automação e cadeia de ferramentas para fornecer dados de forma rápida e repetível.

2. Iterar (Iterate DataOps)
Pipeline de Dados: Definição de sprints de dados para garantir entrega contínua focada nos negócios.

Descoberta: Utilização de automação para descrever e inferir a semântica dos dados.

Classificação: Transformação dos dados em informações, padronizando glossários e construindo gráficos semânticos.

Qualidade: Avaliação e mitigação da qualidade dos dados, usando políticas e regras para orientar o uso.

Manipulação: Documentação dos processos de manipulação para garantir repetibilidade e rastreabilidade.

Movimentação de Dados: Utilização de ferramentas ETL para mover dados com regularidade e eficiência.

3. Melhorar Continuamente (Continuous Improvement)
Remediação: Análise e resolução de problemas ao longo do pipeline de entrega.

Aprendizado: Cada iteração traz novos conhecimentos que são incorporados de volta ao processo, garantindo um ciclo virtuoso de melhoria contínua.
Estudo de Caso: Análise de Fraudes de Cartão de Crédito
Contexto

Pesquisa da Visa (2018): Descobriu que mais de 80% dos cidadãos europeus usam seus telefones celulares para pagamentos, uma tendência refletida globalmente.

Relatório Mundial de Pagamentos (2019): Volume de transações não monetárias está crescendo rapidamente, especialmente na Ásia (32%) e na Europa, Oriente Médio e África (19%).

Desafio

Fraude de Crédito: Os EUA lideram com 38,6 milhões de perdas relatadas em 2018.

Objetivo: Mitigar o risco de fraudes em transações não monetárias.

Objetivos do Estudo de Caso
Previsão de Transações Fraudulentas: Usar um conjunto hipotético de dados para prever transações fraudulentas.

Sprint de Dados: Definir o objetivo geral de negócios e KPIs para análise de fraudes.

Modelo de IA: Desenvolver um modelo de IA para detectar e impedir fraudes em tempo real.

Metodologia
Enfoque em Princípios de DataOps: Encontrar, usar e integrar dados para o projeto.

Inteligência Encapsulada em IA: Implementar um modelo de IA para análise preditiva.

Limitações
Objetivo Ilustrativo: Estudo de caso é para ilustrar os princípios, não para ser o padrão-ouro na detecção de fraudes.

Maximiza a velocidade de entrega de insights com ferramentas automatizadas.

Criar uma base confiável para IA
Identificar fontes de dados diversas (tradicionais e novas, como e-mails, blogs).
Organizar dados para análise, garantindo precisão e confiabilidade.
Melhorar a capacidade de encontrar e entender ativos de dados.
Etapas fundamentais para dados
Analisar dados de todas as fontes relevantes para tomar decisões informadas.
Preparar dados organizados e compreensíveis.
Canalizar dados para modelos de análise e IA.
Processo de organização dos dados
Pipeline de dados repetível para garantir fluxo contínuo.
Integração de ponta a ponta e automação para resultados rápidos.
Ingestão de dados através de canais bem definidos.
Metodologia suportada por ferramentas de software
Necessidade de suportar metodologias com software adequado.
A automação é crucial para escalar o processo e atender ao volume de dados.
Importância de uma estratégia de dados
Entender o cenário atual de dados e evoluir para onde se deseja estar.
Priorizar o que a organização deseja manter e o que deseja mudar.
Conectar a estratégia de dados ao plano de negócios, IA e análise.
Componentes de uma estratégia de dados
Reconhecer dados como um ativo estratégico.
Impulsionar inovação e remover fatores de bloqueio.
Incluir uma arquitetura geral e ser acionável.
Plano de adaptação do roteiro para impulsionar a inovação.
Objetivos da estratégia de dados
Fornecer os dados necessários para apoiar as metas de negócios.
Esclarecer a natureza dos dados necessários e como gerenciá-los.
Descrever a arquitetura de dados (coleta, armazenamento, transformação, movimentação e consumo de dados).
Necessidade de uma estratégia de dados antes de usar DataOps
Fornecer estrutura para decidir como gerenciar dados na organização.
Definir como determinar a qualidade dos dados e quando realizar a correção de qualidade.
Perspectivas da estratégia de dados
O que precisa ser feito (obrigatório) e o que colocará a organização à frente dos concorrentes.
Incluir regras que regem os repositórios de dados e sistemas para conectar dados aos processos de negócios.
Elementos principais da estratégia de dados
Necessidades comerciais de curto e longo prazo.
Medição da estratégia de dados (fator crítico de sucesso e KPIs).
Consideração de pessoas e processos (partes interessadas na validação do plano).
Necessidades de dados, topologia e fluxos de dados.
Recursos de IA e tecnologia.
Análise de lacunas e plano de ação
Criar uma análise de lacunas em relação ao estado atual.
Desenvolver um plano de ação com tarefas organizadas em sequência com proprietários e datas.
Cenário de fraude no banco
O banco está perdendo fundos devido a fraudes on-line.
Há vários sistemas com dados duplicados devido a fusões e aquisições.
Desenvolvimento de modelos de aprendizado de máquina
Demonstrar os benefícios da automação para verificação de transações.
Desenvolver modelos de aprendizado de máquina para detectar fraudes.
Desafios na qualidade dos dados
Sistemas de dados duplicados e dispersos.
Herdar infraestrutura tecnológica de bancos adquiridos.
Ameaças à qualidade dos dados
Dificuldades em consolidar dados de diferentes sistemas.
Impacto nos sistemas operacionais ao consolidar silos de dados.
Necessidade de equilibrar custos de nova arquitetura de dados com latência de acesso.
Estratégia de dados para o banco
Priorizar entre consolidação de sistemas de dados ou virtualização de dados.
Considerar a latência de acesso e os tempos de resposta em tempo real para processamento de transações.
Criar um plano de ação objetivamente benéfico para a organização.
Oportunidades para um novo diretor de dados
Intermediar um plano que aproveite os dados sem obstáculos de propriedade prévia.
Reunir partes interessadas para trabalhar em um objetivo comum.
Implementar ferramentas e métricas de Data Ops para metas de qualidade consistentes.
Usar terminologia comercial comum para fornecer uma visão padrão dos dados.
Objetivo do DataOps
Permitir um processo repetível para criar e implantar análises e pipelines de dados.
Foco no objetivo comercial e na entrega rápida dos dados necessários.
Estrutura e dinâmica da equipe
Equipes organizadas para serem focadas no resultado.
Incluir habilidades empresariais e conhecimento técnico.
Entender o que é necessário, como será usado e como encontrar os dados.
Formação e organização da equipe
Reunir membros com habilidades diversas para formar um conjunto coeso.
Aumentar a velocidade de entrega com a automação.
Evoluir a cultura interna para ser orientada por dados.
Promover a comunicação e colaboração entre todas as partes envolvidas.
Desafios históricos
Organizações geralmente isoladas na abordagem de dados.
Dados de propriedade da TI e gerenciados separadamente por linhas de negócios.
Adotando DataOps
Melhorar as linhas de comunicação para facilitar a entrega rápida dentro das diretrizes da estratégia de dados.
Combinar conhecimento comercial e técnico nas equipes.
Organizar as equipes para entregar de forma eficaz com compreensão clara de suas metas diárias.
Automação e uso de ferramentas
Uso de automação para operar com velocidade.
Padronização na organização e distribuição das tarefas.
Calibrar as tarefas em relação aos objetivos a qualquer momento.
Monitoramento e indicadores de desempenho
Uso de dados para monitorar o progresso e KPIs para sprint de dados.
Atualização regular dos KPIs para permitir que a equipe e partes interessadas entendam o progresso.
Aqui está um resumo dos pontos principais sobre a metodologia DataOps e a estrutura da equipe em tópicos:
Funcionamento das equipes em DataOps
Pequenos grupos focais de 5 a 10 pessoas.
Especialistas em suas funções.
Fluxo de dados da forma bruta até serem prontos para consumo.
Uso máximo de automação e criação de artefatos de governança.
Matriz RACI
Define funções ou responsabilidades: Responsável, Acionável, Consultada e Informada.
Garante comunicação clara e responsabilidade.
Integração nas ferramentas de governança para colaboração e transparência.
Estrutura de equipe ideal
Clareza de autoridade e função esperada de cada pessoa.
Combinação de conhecimento institucional e novos conhecimentos.
Uso de automação e ferramentas para organizar e distribuir cargas de trabalho.
Monitoramento do progresso com painéis e KPIs para Data Sprint.
Organização geral e patrocínio
Estrutura organizacional típica que apoia a equipe DataOps.
Importância do esforço de toda a empresa e patrocínio executivo.
Comitê Gestor Executivo responsável pela seleção das iniciativas e alocação de recursos.
Conselho de Governança de Dados Corporativos que define políticas e regras.
Equipes relacionadas
Grupo de trabalho de Arquitetura de Dados: arquitetos de dados, modeladores de dados, administradores de banco de dados.
Escritório de Governança de Dados: administrador de metadados, analista de governança de dados.
Aspectos pessoais e culturais
Habilidades e experiência são essenciais para uma equipe bem-sucedida de DataOps.
Patrocínio e interesse das partes interessadas executivas são fundamentais.
Cultura de comunicação e colaboração para entrega rápida e eficiente.
 Objetivo da cadeia de ferramentas DataOps
Obter valor da automação disponível para fornecer dados prontos para negócios.
Encarar desafios nos processos manuais redundantes e lacunas de comunicação.
Benefícios de uma cadeia de ferramentas inteligente
Agregar valor comercial de forma rápida e repetida.
Superar obstáculos comuns como problemas de pipeline, inconsistência de código e dependências técnicas.
Desafios enfrentados por equipes
Identificação de problemas de pipeline e inconsistência de código.
Infraestrutura e operações desafiadoras.
Processos manuais levando a longos tempos de resposta, erros frequentes e baixa repetibilidade.
Processos isolados levando a dados instáveis e resultados imprevisíveis.
Componentes de uma cadeia de ferramentas DataOps
Conectar pessoas e processos à tecnologia.
Automatizar tarefas redundantes.
Medir o progresso com KPIs e publicar o status atual.
Garantir entrega confiável de dados prontos para negócios usando um processo repetível.
Etapas de implementação da cadeia de ferramentas DataOps
Gerenciamento de controle de origem: Automatizar o pipeline de dados de ponta a ponta, usando ferramentas como o GitHub.
Automatização dos processos e fluxo de trabalho: Serviços automatizados de curadoria de dados, gerenciamento de metadados, governança de dados, etc.
Testes de dados e lógica: Testar entradas e saídas para garantir precisão e qualidade consistente dos dados.
Fluxos de trabalho paralelos: Pipeline de valor e pipeline de inovação para implantar mudanças sem interromper os fluxos de dados atuais.
Comunicação e gerenciamento de processos: Notificações eficientes e automatizadas usando ferramentas como o Slack ou Trello.
A aplicação das cinco etapas da cadeia de ferramentas DataOps em qualquer ambiente operacional:

Gerenciamento de controle de origem

Uso de ferramentas como GitHub para armazenar e gerenciar todas as alterações no código e na configuração.

Automação do pipeline de dados de ponta a ponta.

Automatização dos processos e fluxo de trabalho

Serviços automatizados de curadoria de dados, gerenciamento de metadados, governança de dados, gerenciamento de dados mestres e interação de autoatendimento.

Flexibilidade de tempo de execução.

Testes de dados e lógica

Testar entradas e saídas e aplicar a lógica de negócios.

Garantir precisão, consistência e qualidade dos dados em cada estágio.

Fluxos de trabalho paralelos

Pipeline de valor: Criação de valor contínuo.


Pipeline de inovação: Desenvolvimento de novas análises e sua integração à produção.

Evitar interrupções nos fluxos de dados atuais.

Comunicação e gerenciamento de processos

Notificações eficientes e automatizadas para partes interessadas usando ferramentas como Slack ou Trello.

Monitoramento contínuo de KPIs e comunicação colaborativa.

Exemplo de aplicação prática:

Desafio: Pipeline de dados do cliente não cumpria contratos de nível de serviço, resultando em relatórios atrasados e imprevisíveis.

Solução: Implementação de uma cadeia de ferramentas DataOps com:

Kibana e Grafana para revisão do pipeline de dados e utilização de recursos.

Kafka e Git para automação de processos e comunicação.

Entrega automatizada ao Git, testes de implantação bem-sucedidos e monitoramento contínuo.

Planejamento ágil para integração de novos dados de filiais sem impactar a produção.

 O estabelecimento de uma linha de base para a governança de dados na metodologia DataOps:
Importância da linha de base para a governança
Depende da maturidade do gerenciamento de informações e dados, tolerância a riscos e processos de litígio e descoberta eletrônica.
Privacidade de dados como uma consideração chave, mas há outras considerações de governança importantes.
Considerações de governança
Necessidade de influenciar os processos de negócios e de governança de dados.
Incorporação às classificações de dados e políticas de gerenciamento de dados.
Equipe de operações de dados
Composta por membros de TI, negócios e outras disciplinas.
Garantia de adesão às técnicas relevantes.
Desenvolvimento de modelos e padrões operacionais
Fornecer orientação e proteções para garantir a governança de dados.
Termos de negócios em uma estrutura reutilizável.
Recursos básicos de classe empresarial contendo termos comerciais, dados referenciados e classificações de dados.
Categorização e classificação dos dados
Necessidade de organizar dados em agrupamentos lógicos.
Domínios de dados como categorias de dados comerciais de alto nível (ex.: cliente, produto, transação).
Estrutura amigável para os negócios dos dados da organização.
Atribuição de responsabilidade e responsabilidade pelos dados (administradores de dados).
Glossário de negócios
Lista alfabética de termos com definições.
Facilitar o acesso e a compreensão dos dados.
Exemplo: Termos comerciais padronizados para conectar e mapear artefatos de dados físicos.
Governança e supervisão
Estabelecimento da linha de base:
Modelos e padrões para acessar, integrar, limpar, governar, armazenar e preparar dados.
Processo de ingestão, armazenamento, organização e manutenção dos dados.
Gerenciamento de dados:
Modelar dados corporativos considerando necessidades informacionais dos processos e unidades de negócios.
Definir níveis de privilégios de acesso para dados corporativos.
Governança da informação:
Estratégia geral das informações dentro de uma organização.
Equilibrar o risco e o valor das informações.
Ajudar na conformidade legal, transparência operacional e redução de despesas com detecção legal.
Classificação de informações para proteção, acessibilidade e retenção.
Traduzir políticas em regras aplicáveis, monitoradas e auditadas.
Requisitos regulatórios, necessidades comerciais e obrigações legais
Requisitos regulatórios:
Regras e regulamentos específicos de setor, país, localização ou tipo de dados.
Regulamentos de privacidade e segurança (GDPR, CCPA, NIST, etc.).
Regulações sobre retenção, uso e divulgação de dados.
Necessidades comerciais:
Análise, taxonomia, classificação e precisão dos dados.
Conflito entre necessidades comerciais e regulamentações de privacidade ou retenção.
Identificação ou anonimização dos dados para análise.
Obrigações legais:
Litígios e requisitos de auditoria.
Retenção legal de dados em casos de litígios.
Influências externas
Riscos de reputação: Impacto de violação de dados.
Multas e penalidades: Consequências financeiras de não conformidade.
Terceiros e concorrência: Influência no uso e compartilhamento de dados.
Violações de dados: Consideração externa mais comum e cara.
Aqui está um resumo dos pontos principais sobre a entrega de valor comercial na metodologia DataOps:
Foco no valor comercial
Entregar valor comercial rapidamente às partes interessadas e consumidores de dados.
Foco na velocidade de entrega dos dados.
Ênfase em pequenas entregas iterativas.
Escopo razoável dos dados necessários, balanceando entre detalhes específicos e amplitude de fontes.
Estrutura da equipe de DataOps
Composta por representantes de toda a organização.
Envolvimento das melhores pessoas disponíveis, com experiência em negócios e administração de dados.
Maximização da produtividade da equipe e justificativa do engajamento com retorno à organização.
Requisitos de dados e sprints de dados
Descrição clara dos requisitos de dados.
Reunião dos requisitos em sprints de dados para maximizar cada iteração.
Aprendizado com as melhores práticas do DevOps.
Gerenciamento do fluxo de trabalho
Gerenciamento eficiente do fluxo de trabalho desde o início até a entrega dos dados.
Transformação de matérias-primas em produtos acabados de acordo com a demanda dos consumidores.
Evitar a abordagem cega de disponibilizar tudo de todas as fontes de dados.
Foco no consumidor de dados
Identificação do que é exigido pelos consumidores de dados.
Concentração no valor obtido ao disponibilizar determinados dados para uso específico.
Consideração da urgência e do risco de não entrega.
Criação de pacotes de requisitos
Descrição padrão do que constitui uma unidade lógica de trabalho para uma necessidade específica de dados.
Criação de pacotes que representam os requisitos (histórias de dados, tarefas de dados, problemas de dados).
produção de dados e a gestão de problemas de entrega de dados
Status geral dos pipelines de dados
Considerar o inventário de dados e classificar os elementos críticos.
Conhecimento das fontes de dados e problemas de acesso aos dados.
Definições comuns de dados entre empresas ou segmentação por linha de negócios.
Trabalho das equipes multifuncionais
Avaliar como as equipes trabalham juntas atualmente.
Melhorar a colaboração para ajudar a equipe de operações de dados a se unir.
Avaliação da qualidade e governança
Aplicar regras de governança e articular políticas de dados.
Reunir um entendimento comum de boa qualidade.
Descrever regras de dados de boa qualidade consistentemente em todas as fontes e usos dos dados.
Apoio à governança
Apoio claro à governança em toda a organização.
Aplicação rigorosa das políticas de governança para todos os consumidores de dados.
Estabelecimento de fluxos de dados regulares
Padronizar fluxos de dados existentes e novos pipelines de dados.
Priorizar problemas no fluxo de dados com base em prioridades de negócios.
Tarefas de dados
Descrever o trabalho necessário para agregar valor comercial.
Eliminar gargalos na entrega de dados.
Complementar dados existentes ou fornecer novos dados.
Indicar claramente o valor comercial das informações.
Indicadores-chave de desempenho (KPIs)
KPIs de inventário de dados, governança de dados e pipeline de dados.
Medir o progresso e a integridade do projeto.
Avaliar a qualidade das fontes de dados e o impacto da baixa qualidade.
Medir a complexidade e a eficácia da consolidação e integração de dados.

Descrição da tarefa de dados
Listar os dados necessários, identificando os elementos de dados críticos (CDEs).
Compreender os processos de negócios atuais e as informações coletadas.
Definir elementos de dados críticos que não estão disponíveis e precisam ser obtidos internamente ou externamente.
Exemplo de tarefa de dados
Continuidade dos negócios e retenção de talentos:
Examinar a remuneração total de executivos.
Considerar salário existente e elementos de remuneração.
Benchmarking com dados externos para garantir níveis salariais do setor.
Trabalho com a equipe de operações de dados
Descrever as informações necessárias em linguagem comercial geral.
Utilizar termos comerciais existentes no glossário.
Adicionar fontes de dados estimadas aos requisitos da tarefa.
Planejamento do Data Sprint
Manter uma lista bem cuidada de tarefas de dados.
Priorizar itens no backlog para garantir que a equipe se concentre em seu sprint atual.
Definir a duração do sprint para equilibrar urgência e retorno valioso.
Atribuição de pontuação às tarefas de dados
Avaliar o valor da tarefa com base em impacto nas vendas, retenção de clientes, benefícios de marketing e eficiências operacionais.
Subtrair a dificuldade relativa de entrega para obter uma pontuação geral.
Aplicar uma abordagem padrão para todas as tarefas de dados.
Exemplo de seguro
Minimização de pagamentos de sinistros:
Plano de ação para contatar clientes proativamente com conselhos sobre eventos climáticos.
Impacto comercial principal: redução de pagamentos de sinistros.
Impactos secundários: satisfação do cliente e melhoria na relação com a seguradora.
KPIs: número de grandes eventos de tempestade monitorados, tipo de reclamação, custo do programa de comunicação, número de clientes envolvidos, valor do pagamento, e pontuação líquida do promotor do cliente.
KPIs do inventário de dados, governança e pipeline de dados
Medir o progresso e a integridade da tarefa de dados.
Avaliar a qualidade das fontes de dados.
Medir a complexidade e a eficácia da consolidação e integração de dados.

focando na entrega de valor comercial e a gestão de sprints de dados:
Planejamento do Sprint
Sprint: Período definido para concluir e preparar trabalho para análise.
Considerar o acúmulo de tarefas de dados ao planejar o sprint.
Início com poucas tarefas de dados para desenvolver habilidades.
Dívida Técnica
Trabalho necessário que não entrega diretamente dados empresariais, mas é essencial.
Inclui aprimorar recursos de painel, analisar problemas de desempenho, entre outros.
Incluir medidas para eliminar dívidas técnicas em cada sprint.
Combinação de Tarefas de Dados
Combinar tarefas de dados com alta sobreposição em fontes críticas.
Proporção ideal de quatro tarefas de dados para uma tarefa de dívida técnica.
KPIs do Sprint
Combinação de KPIs das tarefas de dados.
Acompanhar progresso na qualidade, conformidade e disponibilidade dos dados.
Estudo de Caso: Fraude em Compras Online
Identificação de transações fraudulentas usando padrões históricos de transações.
Elementos de dados necessários: dados de clientes (idade, ocupação), dados de transação (local, valor), informações de crédito, etc.
Fontes de dados: sistemas internos e fontes externas de benchmarking.
KPIs de Governança de Dados
Alta pontuação de qualidade necessária para reduzir falsos positivos.
Implementação de regras de privacidade e proteção de dados sensíveis.
Backlog de Dados
Lista priorizada de tarefas de dados, descritas pelo valor comercial ou eliminação de dívidas técnicas.
Seleção de tarefas de maior prioridade para sprints de dados.
Entrega de Valor Comercial
Foco no impacto nos negócios e na urgência.
Descrição padrão do impacto e monitoramento do progresso.
A
Definição de Classificação de Dados
Análise de dados estruturados ou não estruturados e organização em categorias com base em características comuns.
Estruturas significativas chamadas taxonomias são usadas para documentar uso, propriedade, sensibilidade, retenção, etc.
Importância da Classificação de Dados
Facilita o entendimento e a confiança nos dados pelos usuários.
Dados não classificados podem ser mais difíceis de entender e menos adequados para uso em relatórios ou análises.
Taxonomias de Classificação Principais
Domínio de Dados: Organiza elementos de dados em áreas temáticas baseadas em sua finalidade comercial e uso.
Confidencialidade: Indica a sensibilidade dos dados e as medidas de segurança necessárias.
Retenção: Designa o período de retenção dos dados com base em requisitos normativos e políticas de negócios.
Processo de Classificação de Dados
Estabelecer Objetivos de Classificação:
Otimizar recursos de pesquisa, identificar arquivos confidenciais, proteger dados críticos, etc.
Criar Fluxos de Trabalho:
Definir processos para classificar dados, digitalizar novos dados e criar novos critérios de classificação.
Determinar Categorias e Critérios:
Usar tags e rótulos para definir tipo, confidencialidade e integridade dos dados.
Definir Resultados e Uso:
Organizar os resultados para facilitar a análise.
Exemplos de Objetivos de Classificação
Otimizar indexação de dados, identificar propriedade intelectual, cumprir regulamentações como HIPAA ou GDPR, otimizar armazenamento, etc.
avaliação e o gerenciamento da qualidade dos dados 
Qualidade de Dados
Capacidade dos dados de satisfazer os requisitos estabelecidos de uma empresa.
Dados de alta qualidade são adequados para uso nas operações, tomada de decisões e planejamento.
Dados de alta qualidade são livres de defeitos e possuem os recursos desejados.
Impacto da Baixa Qualidade de Dados
Pode causar um impacto financeiro significativo (exemplo: $15 milhões por ano, segundo a Gartner).
Afeta negativamente todas as organizações em vários níveis.
Dados de alta qualidade são um ativo estratégico e uma vantagem competitiva.
Benefícios dos Dados de Alta Qualidade
Melhor tomada de decisão baseada em dados.
Maior satisfação do cliente.
Maior eficiência operacional.
Cumprimento dos requisitos de conformidade legal e regulamentar.
Melhores análises e facilitação de aprendizado de máquina e inteligência artificial.
Quem Precisa de Dados de Alta Qualidade?
Oficiais de qualidade de dados, administradores de dados e analistas de qualidade de dados.
Necessário para medir, monitorar e resolver problemas de qualidade de dados.
Suporte para descoberta, classificação em grande escala e correção de qualidade.
Dimensões de Qualidade de Dados
Conjunto de atributos que representam um único aspecto da qualidade dos dados.
Dimensões mais usadas incluem: precisão, integridade, consistência e exclusividade.
Nem todas as dimensões são igualmente importantes para todos os fins.
Estrutura de Gerenciamento de Qualidade de Dados
Definir a Qualidade dos Dados: Estabelecer requisitos específicos.
Avaliar a Qualidade dos Dados: Medir as dimensões significativas para a empresa.
Corrigir os Problemas de Qualidade dos Dados: Implementar correções necessárias.
Monitorar a Qualidade dos Dados Continuamente: Garantir manutenção da qualidade ao longo do tempo.
Essa estrutura permite que as organizações gerenciem a qualidade dos dados de forma estratégica e melhorem continuamente.
Aqui está um resumo dos pontos principais sobre o gerenciamento de qualidade de dados e entidades na metodologia de aplicativos de dados:
Definição da Qualidade dos Dados
Definir o escopo da qualidade dos dados analisando os elementos críticos de dados.
Estabelecer dimensões de qualidade de dados a serem medidas.
Definir e acordar um limite aceitável com as empresas.
Analisar e associar metadados adequadamente aos elementos críticos de dados.
Avaliação da Qualidade dos Dados
Avaliar a qualidade dos dados em relação às dimensões definidas.
Realizar perfis de dados para entender conteúdo, estrutura e qualidade dos dados.
Desenvolver e automatizar regras de qualidade de dados.
Revisar, analisar e comparar resultados de testes com o limite de aceitação.
Identificar exceções críticas de qualidade de dados e desenvolver recomendações para resolvê-las.
Correção da Qualidade dos Dados
Implementar medidas para resolver problemas de qualidade de dados e eliminar a causa raiz.
Usar rotinas de limpeza de dados para corrigir problemas como duplicatas e valores nulos.
Aplicar técnicas de validação de dados para reduzir entrada de dados incorretos.
Identificar e remediar exceções sistemáticas de dados no futuro.
Combinação e Sobrevivência
Identificar dados semelhantes e determinar se representam a mesma entidade.
Definir regras de negócios para determinar correspondências entre registros.
Criar um único registro por entidade (disco dourado) a partir de vários registros vinculados.
Monitoramento Contínuo da Qualidade dos Dados
Monitorar a qualidade dos dados em intervalos regulares.
Criar perfis de dados e verificar registros em relação a regras de qualidade definidas.
Exibir resultados em um painel de controle de qualidade de dados.
Emitir alertas em caso de problemas de qualidade de dados e notificar os usuários apropriados.
Compartilhar ativos de dados com etiqueta de qualidade validada no catálogo.

Revisão e Refinamento de Políticas
Revisar políticas básicas à medida que mais informações são conhecidas.
Expandir e refinar políticas com base em características de classificação dos dados.
Aplicar políticas de proteção, acessibilidade e retenção dos dados.
Processo de Estabelecimento de Políticas
Definir políticas com base nas características dos dados.
Avaliar a implementação da política.
Promulgar regras para implementar as políticas.
Políticas de Proteção e Acessibilidade
Proteção: Garantir a segurança e privacidade dos dados confidenciais.
Acessibilidade: Definir quem tem acesso aos dados e como esses dados podem ser utilizados.
Retenção: Estabelecer períodos de retenção de dados com base em regulamentações e políticas de negócios.
Exemplo de Estudo de Caso
Cientistas de dados avaliando a detecção de fraudes em uma instituição financeira.
Necessidade de acessar sistemas transacionais, CRM e dados de crédito externos.
Considerações regulatórias: PCI, PII, GDPR, CCPA, LGPD.
Regulamentações e Requisitos
GDPR: Regulamento Europeu de Proteção de Dados.
CCPA: Lei de Privacidade do Consumidor da Califórnia.
LGPD: Lei Geral de Proteção de Dados no Brasil.
Regulamentações bancárias adicionais: PCI, FFIEC, SOC, BCBS.
Aplicação de Regras
Aplicar regras específicas para dados altamente confidenciais (ex.: número do cartão de crédito).
Considerar desidentificação ou anonimização de dados para análise quando necessário.
Monitorar, auditar e verificar a aplicação das políticas.
Armazenamento e Retenção
Regulamentações limitam por quanto tempo as informações podem ser retidas.
Considerar implicações de dados atuais e precisos.
Aqui está um resumo dos pontos principais sobre a preparação de dados e autoatendimento na metodologia DataOps:
Preparação de Dados
Manipulação ou pré-processamento de dados brutos para torná-los prontos para análise.
Tarefas incluídas: carregamento/ingestão de dados, fusão de dados, limpeza de dados, aumento de dados e entrega de dados.
Encontrar os Dados Certos
Uso de uma variedade de critérios de pesquisa e filtragem de resultados.
Análise dos ativos de dados dos candidatos através de perfilamento de conteúdo e visualização da linhagem de dados.
Avaliação das amostras e informações de perfil para garantir que os dados atendam às necessidades do consumidor.
Catálogo de Dados Inteligente
Permite ao consumidor de dados escolher um catálogo específico ou pesquisar em todos os catálogos disponíveis.
Recomenda ativos de dados com base em padrões de acesso ou ativos adicionados recentemente.
Oferece opiniões de outros consumidores através de avaliações dos ativos de dados.
Linhagem de Dados
Importante para entender a jornada dos dados: fontes, transformações aplicadas e uso final.
Ajuda a explorar como os dados fluem pelo pipeline e estabelecer confiança nos dados.
Visualização de Dados
Permite que o consumidor de dados trabalhe diretamente com os dados e veja os resultados das operações aplicadas.
Prototipagem rápida para garantir que os requisitos de dados sejam atendidos.
Engenharia de Dados
Quando os dados atendem às necessidades do consumidor, engenheiros de dados podem planejar a disponibilização regular dos dados.
Planejamento do pipeline de dados para entrega de acordo com um cronograma.

Movimentação e Integração de Dados
Movimentação de dados: Transferência de dados de um repositório para um ou mais outros repositórios de dados.
Integração de dados: Alinhamento, transformação e processamento de dados para preparar para análise.
Padrões Comuns de Integração de Dados
ETL (Extração, Transformação e Carregamento):
Extração em massa de dados dos sistemas de origem.
Transformação em massa dos dados.
Carregamento em massa dos dados no sistema de destino.
Virtualização de Dados:
Criação de uma camada virtual que reúne dados de várias fontes em uma única visualização.
Complementa as ferramentas de ETL.
Movimento Orientado a Mensagens:
Agrupa dados em mensagens que podem ser enviadas aos aplicativos em tempo real.
Requer o uso de uma fila de mensagens (ex.: MQ, Kafka).
Replicação de Dados:
Cópia frequente de dados de um banco de dados para acesso em vários sistemas de aplicativos.
Fornece sincronização de dados para gerenciar volumes crescentes de dados e acesso a informações em tempo real.
Atividades Críticas para Projetos de Integração e Movimentação de Dados
Definição do Caso de Uso: Clarificar o objetivo do projeto.
Identificação de Sistemas de Fontes e Alvos: Caracterizar sistemas de origem e destino.
Identificação de Tarefas Críticas de Integração de Dados: Determinar atividades necessárias.
Escolha das Ferramentas de Software: Decidir entre codificação manual e ferramentas comerciais de integração de dados.
Considerações sobre Infraestrutura de Hardware e Software: Definir requisitos de infraestrutura.
Execução no Ambiente de Produção: Planejar a movimentação e integração de dados na produção.
Espero que esse resumo ajude a entender melhor a movimentação e integração de dados na metodologia DataOps! Se precisar de mais alguma coisa, estou à disposição para ajudar.
qui está um resumo dos passos e considerações principais para a movimentação e integração de dados na metodologia DataOps:
Definição do Caso de Uso
Problema Comercial:
Identifique o problema de negócios que você está tentando resolver.
Sistemas Analíticos e de Relatórios:
Determine os sistemas necessários para resolver o problema de negócios.
Sistemas de Origem e de Destino:
Defina os sistemas de origem e destino necessários, além das tarefas de integração e movimentação de dados.
Exemplo: O caso de uso de fraude de cartão de crédito envolve o desenvolvimento de melhores recursos de detecção de fraudes de cartão de crédito em um banco. Os cientistas de dados precisam criar modelos analíticos para melhorar a previsão de transações fraudulentas com cartão de crédito.
Definição dos Sistemas de Origem e de Destino
Avalie as considerações mais importantes para sistemas de origem e destino.
Tarefas de Movimentação e Integração de Dados
Tarefas Únicas:
Exemplos incluem configuração inicial, carregamento único de dados, e transformação inicial de dados.
Tarefas Recorrentes:
Exemplos incluem atualizações periódicas, sincronização contínua e monitoramento regular.
Escolha das Ferramentas de Software
Decidir entre codificação manual e ferramentas comerciais de integração de dados.
Considerações:
Facilidade de uso
Eficácia
Custo total de propriedade
Design de Trabalho
Portabilidade: Criar uma vez e ser executado em qualquer lugar.
Reutilização: Planejar para reutilizar componentes.
Processamento Paralelo: Suporte para processamento paralelo.
Modelos de Implantação: Considerar contêineres, Kubernetes, orquestração e OpenShift.
Decisões de Infraestrutura
Exemplos incluem decisões sobre hardware, software, alta disponibilidade (HA) e recuperação de desastres (DR).
Requisitos para Execução no Ambiente de Produção
Considerar SLAs, alta disponibilidade, escalabilidade e outros fatores críticos para operação contínua.
Seguindo essas etapas e considerações, sua equipe pode realizar uma movimentação e integração de dados bem-sucedida, garantindo que os dados estejam prontos para apoiar a análise de negócios. Se precisar de mais alguma coisa, estou aqui para ajudar!
 qui está um resumo dos pontos principais sobre a fase de melhoria e conclusão na metodologia DataOps:
Melhoria Contínua e Conclusão
Remediação: Analisar problemas, determinar onde devem ser abordados e fornecer um plano de ação.
Iteração Ágil: Incorporar práticas ágeis e de DevOps para reduzir o tempo de ciclo de entrega de dados.
Prototipagem Rápida: Fornecer dados para autoatendimento rapidamente, mesmo que não estejam totalmente completos.
Feedback Rápido: Ciclo de feedback rápido para validar se os dados estão no caminho certo.
Avaliações de Partes Interessadas: Realizadas no final de cada sprint para manter o foco e colaboração.
Identificação de Gargalos e Solução
Etapas Principais:
Identificar o gargalo.
Determinar a causa raiz do gargalo.
Encontrar soluções para eliminar a causa raiz.
Testar a solução para verificar se funciona.
Exemplos:
Gargalo na taxa de transferência: Resolver aumentando o grau de paralelismo.
Feedback sobre reconhecimento de número de seguro: Incluir dados mundiais no escopo do sprint.
Atividades de Conclusão
Artefatos de Governança de Dados: Termos comerciais, classificações, classes de dados, dados de referência, regras de dados, políticas, regras de automação, linhagem de dados e ativos de dados governados.
Processo de Aprovação: Concluir com a aprovação dos consumidores de dados e publicar os artefatos no ambiente de produção.

Revisão do Processo DataOps
Após cada iteração, revisar as pessoas envolvidas, a tecnologia e os aplicativos usados e os processos e fluxos de trabalho do DataOps.
Refinar e mudar a organização, tecnologia e/ou processos conforme necessário.
Fase de Estratégia de Dados
Definir uma estratégia de dados imediata e de longo prazo.
Avaliar se a estratégia está documentada, comunicada, entendida e apoiada pela organização.
Verificar se a tecnologia está pronta para apoiar a estratégia de dados.
Garantir que a estratégia de dados está alinhada com as prioridades de negócios.
Avaliação da Organização do DataOps
Garantir funções e responsabilidades claramente definidas.
Sincronizar objetivos de todos os membros da equipe.
Avaliar comunicação, resolução de disputas, alocação de recursos, perfil de habilidades e requisitos de treinamento.
Automação e Cadeia de Ferramentas
Automatizar o controle do código-fonte, solicitações de alteração do projeto e processos de descoberta e classificação de dados.
Avaliar o grau de automação alcançado e a necessidade de intervenção manual.
Revisar a automação de comunicação, planejamento de projetos, atribuição e reatribuição de tarefas.
Estabelecimento da Linha de Base
Compreender a maturidade organizacional, governança e influências internas e externas.
Verificar a existência de inventário de sistemas, padrões de nomenclatura, políticas de governança definidas e KPIs identificados.
Estabelecimento de Prioridades de Negócios
Definir prioridades de negócios e identificar uma lista priorizada de tarefas de suporte de dados.
Avaliar se as prioridades de negócios estão claramente definidas.
Garantir que as tarefas de dados estão totalmente definidas em termos de pontuação de prioridade, fontes de dados e elementos críticos.
Processo de Descoberta
Mapear dados necessários para as fontes de dados e identificar lacunas e incompatibilidades.
Avaliar o grau de descoberta automatizada alcançado e a precisão dos mapeamentos de dados.
Classificação de Dados
Classificar os itens de dados descobertos e atribuí-los aos termos comerciais.
Avaliar a precisão das classificações de dados.
Qualidade dos Dados
Definir métricas de qualidade, avaliar a qualidade dos dados, corrigir problemas e monitorar a qualidade.
Avaliar o grau de automação na coleta e monitoramento dos KPIs de qualidade dos dados.
Políticas Gerenciadas
Atribuir políticas de governança aos itens e categorias de dados.
Avaliar a eficácia da atribuição de políticas e a necessidade de automação.
Autoatendimento
Permitir que os consumidores de dados encontrem e processem os dados da maneira desejada.
Avaliar a facilidade e precisão de encontrar dados, além da documentação dos dados.
Movimentação e Integração de Dados
Mover dados entre fontes e destinos usando as ferramentas apropriadas.
Avaliar a eficácia das escolhas arquitetônicas e a precisão das estimativas do sprint.
Fase Completa e Aprimorada
Monitorar e avaliar a qualidade dos dados de um sprint específico.
Medir a eficácia do sprint e o envolvimento das partes interessadas.
A implementação contínua do DataOps em toda a organização incentiva a colaboração entre as partes interessadas e garante que os dados sejam usados de maneira eficaz para alcançar resultados comerciais positivos.

